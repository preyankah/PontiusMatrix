{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File sample.csv does not exist: 'sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f6490b3a007e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0minitialDataFrame\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'sample.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitialDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File sample.csv does not exist: 'sample.csv'"
     ]
    }
   ],
   "source": [
    "initialDataFrame = pd.read_csv(r'sample.csv', index_col= 0)\n",
    "display(initialDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------------------------------\n",
    "# Project Name: Python Library for Pontius Matrix\n",
    "# Collaborators: Priyanka Verma, Priscilla Ahn, Max Enger, Jordan Frey\n",
    "# Purpose: Automation of Pontius Matrix Creation\n",
    "# Created: 10/28/2019\n",
    "#---------------------------------------------------------------------------------------------\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "class pontiPy(object):\n",
    "    def __init__(self, dataframe):\n",
    "        \"\"\"Return a new pandas dataframe object.\"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.df_row_col_sums = dataframe.copy(deep=True)\n",
    "        column_names = []\n",
    "        for col in self.dataframe.columns:\n",
    "            column_names.append(col)\n",
    "        self.df_row_col_sums['Col Sum'] = self.df_row_col_sums.sum(axis=1)\n",
    "        self.df_row_col_sums.loc['Row Sum'] = self.df_row_col_sums.sum(axis=0)\n",
    "\n",
    "    # Function to compute Hits\n",
    "    def agreement(self, category = None):\n",
    "        _hits = []\n",
    "        for i in range(len(self.df_row_col_sums)):\n",
    "            # Hits = Diagonal cells\n",
    "            _hits.append(self.df_row_col_sums.iloc[i][i])\n",
    "        # if no category is specified\n",
    "        # len-1 because total hit sum is included in list\n",
    "        if category is None:\n",
    "            return sum(_hits[0:len(_hits)-1])\n",
    "        # List to build contingency table in the contingency() function\n",
    "        elif category == 'CONTINGENCY':\n",
    "            # replace last item with total hits\n",
    "            # right now it is the sum of the matrix\n",
    "            _hits[len(_hits)-1] = sum(_hits[0:len(_hits)-1])\n",
    "            return _hits\n",
    "        # if category is specified, return hits for that category\n",
    "        else:\n",
    "            # return\n",
    "            return _hits[category]\n",
    "\n",
    "    # Function to compute false alarms\n",
    "    def row_disagreement(self, category = None):\n",
    "        _false_alarm = []\n",
    "        # subtract one to get # of categories\n",
    "        # removes row sum from the length\n",
    "        df_length = (len(self.df_row_col_sums) - 1)\n",
    "        for i in range(len(self.df_row_col_sums)):\n",
    "            # False alarms = Column Sum - Hits for each category\n",
    "            _false_alarm.append(self.df_row_col_sums.iloc[i][df_length]-self.df_row_col_sums.iloc[i][i])\n",
    "        # if no category is specified\n",
    "        # len-1 because total false alarm sum is included in list\n",
    "        if category is None:\n",
    "            return sum(_false_alarm[0:len(_false_alarm)-1])\n",
    "        # List to build contingency table in the contingency() function\n",
    "        elif category == 'CONTINGENCY':\n",
    "            # add sum of false alarms to list as last item\n",
    "            _false_alarm[len(_false_alarm)-1] = sum(_false_alarm[0:len(_false_alarm)-1])\n",
    "            return _false_alarm\n",
    "        # if category is specified, return false alarm for that category\n",
    "        else:\n",
    "            return _false_alarm[category]\n",
    "\n",
    "    # Function to compute miss\n",
    "    def column_disagreement(self, category = None):\n",
    "        _miss = []\n",
    "        df_length = len(self.df_row_col_sums)-1\n",
    "        for i in range(len(self.df_row_col_sums)):\n",
    "            # miss = Row Sum - Hits for each category\n",
    "            _miss.append(self.df_row_col_sums.iloc[df_length][i]- self.df_row_col_sums.iloc[i][i])\n",
    "        # if no category is specified\n",
    "        if category is None:\n",
    "            return sum(_miss[0:len(_miss)-1])\n",
    "        # List to build contingency table in the contingency() function\n",
    "        # add sum of misses to list as last item\n",
    "        elif category == 'CONTINGENCY':\n",
    "            _miss[len(_miss)-1] = sum(_miss[0:len(_miss)-1])\n",
    "            return _miss\n",
    "        # if category is specified, return miss for that category\n",
    "        else:\n",
    "            return _miss[category]\n",
    "\n",
    "    # Function to compute Exchange between ALL, ONE or TWO categories\n",
    "    \"\"\"\n",
    "       1. If no category is specified (Total must be false):\n",
    "            Sum of total exchange is returned\n",
    "       2. If total is False and 1 category is specified:\n",
    "            Return is exchange for that category with all other categories + a total value in dict\n",
    "       3. If Total is True and 1 category is specified:\n",
    "            Return is total exchange for that category\n",
    "       4. If 2 categories are specified (Total must be false):\n",
    "            Return exchange between 2 categories\n",
    "    \"\"\"\n",
    "    def exchange(self, category1 = None,category2 = None, Total = False):\n",
    "        _exchange = {}\n",
    "        _categories = range(len(self.df_row_col_sums)-1)\n",
    "        for i in _categories:\n",
    "            # Create a list for every category\n",
    "            _catlist = []\n",
    "            # Exchange calculated between 2 categories\n",
    "            for j in _categories:\n",
    "                if i != j:\n",
    "                    # Create list with each exchange value for category 1\n",
    "                    _catlist.append(min(self.df_row_col_sums.iloc[i][j],self.df_row_col_sums.iloc[j][i]))\n",
    "            # Append exchange list for each category to dictionary\n",
    "            _exchange[i]=_catlist\n",
    "        # A condensed list of category and exchange sum for each\n",
    "        ex_by_category = ({k: sum(v) for k, v in _exchange.items()})\n",
    "        if category1 is None and Total is False:\n",
    "            # Total exchange\n",
    "            return sum(ex_by_category.values())\n",
    "        elif Total is True and category2 is None:\n",
    "            return ex_by_category[category1]\n",
    "        # If one category is specified\n",
    "        # Return is exchange with all categories\n",
    "        # Total must be false since it only applies to ONE category\n",
    "        elif category1 is not None and category2 is None and Total is False:\n",
    "            # Dictionary to return exchanges between cat 1 and all other categories\n",
    "            # Also returns a total exchange for category\n",
    "            _single_category = {}\n",
    "            # iterate through number of categories\n",
    "            for i in range(len(_exchange[category1])):\n",
    "                # Exchange at index 0 = exchange of 0 with category 1 since exchange cannot happen with itself\n",
    "                # Size of list with exchange is # of categories - 1\n",
    "                # If index of list item == category 1, the exchange is for the category after\n",
    "                # Example: Parameter is Category 2\n",
    "                # Exchange for Category 2: {'Category 0': 0, 'Category 1': 30, 'Category 3': 40, 'Total Exchange': 70}\n",
    "                if i != category1:\n",
    "                    # key for dictionary\n",
    "                    _cat_key = 'Category ' + str(i)\n",
    "                    # If i == category, the else statement added that category to dict\n",
    "                    # So this addition will be i+1\n",
    "                    if _cat_key in _single_category.keys():\n",
    "                        _cat_key = 'Category ' + str(i + 1)\n",
    "                        _single_category[_cat_key] = _exchange[category1][i]\n",
    "                    # if category i not in dictionary, add to dictionary\n",
    "                    else:\n",
    "                        _single_category[_cat_key] = _exchange[category1][i]\n",
    "                # Exchange at index 0 = exchange of 0 with category 1\n",
    "                # When index == category1 parameter, the key will be incremented by 1\n",
    "                # Category 1 Exchange with Category 0 = index 0 in list\n",
    "                else:\n",
    "                    _cat_key = 'Category ' + str(i+1)\n",
    "                    _single_category[_cat_key] = _exchange[category1][i]\n",
    "                    _single_category[_cat_key] = _exchange[category1][i]\n",
    "            _single_category['Total Exchange'] = sum(_single_category.values())\n",
    "            return _single_category\n",
    "\n",
    "        # To calculate exchange within pairs, it needs to find the index of the categories in dict\n",
    "        else:\n",
    "            # Categories provided as params cannot be the same since exchange happens in pairs\n",
    "            if category1 == category2:\n",
    "                return 'No Exchange Within The Same Category. Provide Two Different Categories.'\n",
    "            # When cat1 == 0, the index should be 0 for the\n",
    "            if category1 != 0 and category2 != 0 :\n",
    "                # Exchange is with the inverse cell position for the two categories\n",
    "                # The index of other category will be -1 in the second pairing\n",
    "                return min(_exchange[category1][category2-1],_exchange[category2-1][category1])\n",
    "            # If cat 1 is 0, return MIN (0[cat2-1], cat2[0])\n",
    "            elif category1 == 0:\n",
    "                return min(_exchange[category1][category2-1], _exchange[category2][category1])\n",
    "            # If cat 2 is 0, return MIN (cat1[0], cat2[cat-1])\n",
    "            elif category2 == 0:\n",
    "                return min(_exchange[category1][category2], _exchange[category2][category1-1])\n",
    "\n",
    "    # Function to compute quantity between all or one category\n",
    "    # Requires at least 1 category in parameter\n",
    "    def quantity(self, category = None, label = False):\n",
    "        if category is not None:\n",
    "            # Returned as a dictionary\n",
    "            # If no category is specified, return total quantity\n",
    "            _quantity = {}\n",
    "            # Calculate quantity by subtracting false alarms from misses\n",
    "            _q_by_category = self.column_disagreement(category) - self.row_disagreement(category)\n",
    "            # Quantity Labels\n",
    "            # If greater than 0, it is a miss quantity\n",
    "            if _q_by_category > 0:\n",
    "                _quantity['Miss'] = abs(_q_by_category)\n",
    "            # If greater than 1, it is a false alarm quantity\n",
    "            elif _q_by_category < 0:\n",
    "                _quantity['False Alarm'] = abs(_q_by_category)\n",
    "            # If 0, quantity is 0\n",
    "            else:\n",
    "            # if it isn't a miss or false alarm quantity\n",
    "                _quantity['Blank'] = abs(_q_by_category)\n",
    "\n",
    "         # If no category is specified: return the absolute sum of all quantity\n",
    "        # Divide sum quantity by 2\n",
    "        # Label is off by default\n",
    "        if category is None:\n",
    "            _categories = range(len(self.df_row_col_sums) - 1)\n",
    "            _quantity_sum = 0\n",
    "            for i in _categories:\n",
    "                _quantity_sum += abs(self.column_disagreement(i)-self.row_disagreement(i))\n",
    "            return int(_quantity_sum/2)\n",
    "        # If True: it returns the quantity value for that category\n",
    "        elif label is True:\n",
    "            return _quantity\n",
    "        # If False (Default): it returns a dictionary\n",
    "        # Dictionary Key = Miss/False Alarm/Blank label\n",
    "        # Dictionary Value = Quantity value for the key\n",
    "        elif label is False:\n",
    "            return list(_quantity.values())[0]\n",
    "\n",
    "    # Function to compute size for all or one category\n",
    "    # Axis must be specified when category is specified\n",
    "    # Determines if row or col sum for category will be returned\n",
    "    def size(self, category = None, axis= None, Total = False):\n",
    "        # size of the data frame is returned\n",
    "        if category is None and axis is None:\n",
    "            return self.df_row_col_sums.at['Row Sum', 'Col Sum']\n",
    "        # return col or row sum for category depending on axis\n",
    "        # An axis (x or y) must be provided with a category\n",
    "        elif category is not None and axis is not None:\n",
    "            if Total is False:\n",
    "                # If x is specified, return col sum for category\n",
    "                if axis.lower() == 'x':\n",
    "                    _col_sum = self.df_row_col_sums['Col Sum'][category]\n",
    "                    return _col_sum\n",
    "                # If y is specified, return row sum for category\n",
    "                elif axis.lower() == 'y':\n",
    "                    _row_sum = self.df_row_col_sums.loc['Row Sum'][category]\n",
    "                    return _row_sum\n",
    "                # if axis isn't specified, return the sum of col and row sum for category\n",
    "            else:\n",
    "                # Get row\n",
    "                if axis.lower() == 'x':\n",
    "                    _col_sum = self.df_row_col_sums.iloc[category]\n",
    "                    x_dict = _col_sum.to_dict()\n",
    "                    # Remove col sum and False Alarms if they exist\n",
    "                    x_dict.pop('Col Sum', None)\n",
    "                    x_dict.pop('False Alarms', None)\n",
    "                    return x_dict\n",
    "                # If y is specified, return col for category\n",
    "                elif axis.lower() == 'y':\n",
    "                    # list of i\n",
    "                    index_list = self.df_row_col_sums.index\n",
    "                    for col in index_list:\n",
    "                        pos = (self.df_row_col_sums.index.get_loc(col))\n",
    "                        if pos == category:\n",
    "                            y_dict = self.df_row_col_sums.get(col).to_dict()\n",
    "                            # Remove Row Sum and Misses if they exist in dictionary\n",
    "                            y_dict.pop('Row Sum', None)\n",
    "                            y_dict.pop('Misses', None)\n",
    "                            return y_dict\n",
    "        else:\n",
    "            return(self.size(category, axis = 'x') + self.size(category, axis = 'y'))\n",
    "\n",
    "    # Function to compute difference for all or one category\n",
    "    def difference(self, category = None):\n",
    "        # if no category is specified, return total size-hits\n",
    "        if category is None:\n",
    "            _total_diff = self.size() - self.agreement()\n",
    "            return _total_diff\n",
    "        # if category is specified: return size-2*hits for that category\n",
    "        else:\n",
    "            return self.size(category) - 2*(self.agreement(category))\n",
    "\n",
    "    # Function to compute total shift or shift for one category\n",
    "    def shift(self, category = None):\n",
    "        if category is None:\n",
    "            total_shift = self.difference() - self.quantity() - self.exchange()\n",
    "            return total_shift\n",
    "        else:\n",
    "            return (self.difference(category)-self.quantity(category)-(2*self.exchange(category, Total = True)))/2\n",
    "\n",
    "    # Generate final matrix\n",
    "    # This function will call previous functions\n",
    "    def matrix(self):\n",
    "        _matrix = self.df_row_col_sums.copy(deep=True)\n",
    "        miss_row = self.column_disagreement('CONTINGENCY')\n",
    "        # Add a blank item since the False Alarm column will not have misses\n",
    "        # Add a blank item since the False Alarm column will not have misses\n",
    "        # This is required since the list size will differ from matrix size\n",
    "        miss_row.append('')\n",
    "        # Add False alarm to matrix\n",
    "        _matrix[\"Row Disagreement\"] = self.row_disagreement('CONTINGENCY')\n",
    "        # Add Misses to matrix\n",
    "        _matrix.loc['Column Disagreement'] = miss_row\n",
    "        # Rename columns for display\n",
    "        _matrix = _matrix.rename({'Col Sum': 'Sum'}, axis=1)\n",
    "        _matrix = _matrix.rename({'Row Sum': 'Sum'}, axis=0)\n",
    "        return _matrix\n",
    "\n",
    "    def entrySize_sam(self):\n",
    "        self.nCategories = len(self.dataframe.columns)\n",
    "        self.df_list = self.dataframe.values.tolist()\n",
    "\n",
    "        self.df_plot = self.dataframe.copy(deep=True)\n",
    "        # delete sum column and row\n",
    "        self.df_plot.loc[\"Miss\"] = self.column_disagreement('CONTINGENCY')[:-1]\n",
    "        self.df_plot.loc[\"False Alarm\"] = self.row_disagreement('CONTINGENCY')[:-1]\n",
    "\n",
    "        # dynamically add labels in EntrySize plot based on x, y pos on plot\n",
    "        x_pos = []\n",
    "        for i in range(0, self.nCategories):\n",
    "            row_hit_sum = 0\n",
    "            for j in range(0, i):\n",
    "                row_hit_sum += (self.df_list[i][j])\n",
    "            row_hit_sum = (self.df_list[i][i] / 2) + row_hit_sum\n",
    "            x_pos.append(row_hit_sum)\n",
    "\n",
    "        fig = px.bar(self.df_plot, y=self.df_plot.index, x=self.df_plot.columns,\n",
    "                     height=350, orientation='h', width=600,\n",
    "                     opacity=1, color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "                     template=\"simple_white\")\n",
    "        fig.update_xaxes(tickvals=[0, 500, 1000, 1500, 2000, 2500])\n",
    "\n",
    "        layout = fig.update_layout(\n",
    "            font=dict(family=\"Trebuchet MS\", size=12),\n",
    "            hovermode=False,\n",
    "            paper_bgcolor='rgba(0,0,0,0)',\n",
    "            plot_bgcolor='rgba(0,0,0,0)',\n",
    "            yaxis=dict(autorange=\"reversed\", type='category', title='Table Feature',\n",
    "                       title_font=dict(size=12, family='Trebuchet MS', color='blue')),\n",
    "            xaxis=dict(title='Entry size as number of Observations', dtick=1,\n",
    "                       title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\",\n",
    "                        x=0.8, title='',\n",
    "                        font=dict(family=\"Trebuchet MS\", size=12, color=\"black\"))\n",
    "        )\n",
    "\n",
    "        for i in range(0, self.nCategories):\n",
    "            fig.add_annotation(x=x_pos[i], y=i, text=\"Hit\", hovertext='Hits for Category 1', showarrow=False,\n",
    "                               font=dict(color='white',\n",
    "                                         family='Trebuchet MS',\n",
    "                                         size=12))\n",
    "        fig.show()\n",
    "    def entrySize(self):\n",
    "        self.nCategories = len(self.dataframe.columns)\n",
    "        self.df_list = self.dataframe.values.tolist()\n",
    "\n",
    "        self.df_plot = self.dataframe.copy(deep=True)\n",
    "        # delete sum column and row\n",
    "        self.df_plot.loc[\"Miss\"] = self.column_disagreement('CONTINGENCY')[:-1]\n",
    "        self.df_plot.loc[\"False Alarm\"] = self.row_disagreement('CONTINGENCY')[:-1]\n",
    "\n",
    "        # dynamically add labels in EntrySize plot based on x, y pos on plot\n",
    "        x_pos = []\n",
    "        for i in range(0, self.nCategories):\n",
    "            row_hit_sum = 0\n",
    "            for j in range(0, i):\n",
    "                row_hit_sum += (self.df_list[i][j])\n",
    "            row_hit_sum = (self.df_list[i][i] / 2) + row_hit_sum\n",
    "            x_pos.append(row_hit_sum)\n",
    "\n",
    "        fig = px.bar(self.df_plot, y=self.df_plot.index, x=self.df_plot.columns,\n",
    "                     height=350, orientation='h', width=600,\n",
    "                     opacity=1, color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "                     template=\"simple_white\")\n",
    "        \n",
    "\n",
    "        layout = fig.update_layout(\n",
    "            font=dict(family=\"Trebuchet MS\", size=12),\n",
    "            hovermode=False,\n",
    "            paper_bgcolor='rgba(0,0,0,0)',\n",
    "            plot_bgcolor='rgba(0,0,0,0)',\n",
    "            yaxis=dict(autorange=\"reversed\", type='category', title='Table Feature',\n",
    "                       title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "            xaxis=dict(title='Entry size as number of Observations', dtick=1,\n",
    "                       title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "            legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\",\n",
    "                        x=0.8, title='',\n",
    "                        font=dict(family=\"Trebuchet MS\", size=12, color=\"black\"))\n",
    "        )\n",
    "\n",
    "        for i in range(0, self.nCategories):\n",
    "            fig.add_annotation(x=x_pos[i], y=i, text=\"Hit\", hovertext='Hits for Category 1', showarrow=False,\n",
    "                               font=dict(color='white',\n",
    "                                         family='Trebuchet MS',\n",
    "                                         size=12))\n",
    "        fig.show()\n",
    "\n",
    "\n",
    "class pontiPy_Change(pontiPy):\n",
    "    def loss(self, category=None):\n",
    "        return self.row_disagreement(category=category)\n",
    "\n",
    "    def gain(self, category=None):\n",
    "        return self.column_disagreement(category=category)\n",
    "\n",
    "    def persistence(self, category=None):\n",
    "        return self.agreement(category=category)\n",
    "\n",
    "    # override method in pontiPy\n",
    "    def matrix(self):\n",
    "        _matrix = self.df_row_col_sums.copy(deep=True)\n",
    "        miss_row = self.column_disagreement('CONTINGENCY')\n",
    "        # Add a blank item since the False Alarm column will not have misses\n",
    "        # This is required since the list size will differ from matrix size\n",
    "        miss_row.append('')\n",
    "        # Add False alarm to matrix\n",
    "        _matrix[\"Loss\"] = self.row_disagreement('CONTINGENCY')\n",
    "        # Add Misses to matrix\n",
    "        _matrix.loc['Gain'] = miss_row\n",
    "        # Rename columns for display\n",
    "        _matrix = _matrix.rename({'Col Sum': 'Sum'}, axis=1)\n",
    "        _matrix = _matrix.rename({'Row Sum': 'Sum'}, axis=0)\n",
    "        return _matrix\n",
    "\n",
    "class pontiPy_Error(pontiPy):\n",
    "    def false_alarm(self, category=None):\n",
    "        return self.row_disagreement(category=category)\n",
    "\n",
    "    def miss(self, category=None):\n",
    "        return self.column_disagreement(category=category)\n",
    "\n",
    "    def hit(self, category=None):\n",
    "        return self.agreement(category=category)\n",
    "\n",
    "    # override method in pontiPy\n",
    "    def matrix(self):\n",
    "        _matrix = self.df_row_col_sums.copy(deep=True)\n",
    "        miss_row = self.column_disagreement('CONTINGENCY')\n",
    "        # Add a blank item since the False Alarm column will not have misses\n",
    "        # This is required since the list size will differ from matrix size\n",
    "        miss_row.append('')\n",
    "        # Add False alarm to matrix\n",
    "        _matrix[\"False Alarm\"] = self.row_disagreement('CONTINGENCY')\n",
    "        # Add Misses to matrix\n",
    "        _matrix.loc['Miss'] = miss_row\n",
    "        # Rename columns for display\n",
    "        _matrix = _matrix.rename({'Col Sum': 'Sum'}, axis=1)\n",
    "        _matrix = _matrix.rename({'Row Sum': 'Sum'}, axis=0)\n",
    "        return _matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame = pontiPy(initialDataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(NewDataFrame.matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NewDataFrame.entrySize_sam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entryIntensity_sam(self):\n",
    "\n",
    "    #get two tables ready; one for row intensity; another for column intensity\n",
    "    self.df_plot_RowIntensity = self.dataframe.copy(deep=True)\n",
    "    self.df_plot_ColumnIntensity = self.dataframe.copy(deep=True)\n",
    "    \n",
    "    # Delete disagreement column and row in the RowIntensity table\n",
    "    \n",
    "    # Devide each cell by the sum for each row in the RowIntensity table\n",
    "    \n",
    "    # Update the RowIntensity table\n",
    "    \n",
    "    # Delete sum column and row in the RowIntensity table\n",
    "    \n",
    "    # Change diagonal cells to 0 in the RowIntensity table\n",
    "    \n",
    "    # plot the RowIntensity table\n",
    "    fig = px.bar(self.df_plot_RowIntensity, y=self.df_plot_RowIntensity.index, x=self.df_plot_RowIntensity.columns,\n",
    "                 height=350, orientation='h', width=600,\n",
    "                 opacity=1, color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "                 template=\"simple_white\")\n",
    "    \n",
    "    # Calculate the gaining category’s uniform transition intensity\n",
    "    \n",
    "    # Delete disagreement column and row in the ColumnIntensity table\n",
    "    \n",
    "    # Devide each cell by the sum for each row in the ColumnIntensity table\n",
    "    \n",
    "    # Update the ColumnIntensity table\n",
    "    \n",
    "    # Delete sum column and row in the ColumnIntensity table\n",
    "    \n",
    "    # Change diagonal cells to 0 in the ColumnIntensity table\n",
    "    \n",
    "    # plot the ColumnIntensity table and add the bars for ColumnIntensity to the fig above\n",
    "    \n",
    "    # update fig layout\n",
    "        layout = fig.update_layout(\n",
    "        font=dict(family=\"Trebuchet MS\", size=12),\n",
    "        hovermode=False,\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        yaxis=dict(autorange=\"reversed\", type='category', title='Table Feature',\n",
    "                   title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "        xaxis=dict(title='Entry intensity as percentage of category size', dtick=1,\n",
    "                   title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\",\n",
    "                    x=0.8, title='',\n",
    "                    font=dict(family=\"Trebuchet MS\", size=12, color=\"black\"))\n",
    "    )\n",
    "    \n",
    "#annotation will be added if a particular transition intensity is greater than the gaining category’s uniform transition intensity\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(NewDataFrame.matrix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.agreement(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.exchange(0, Total=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.shift(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.quantity(0, label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.difference()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewDataFrame.difference(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entrySize_sam(df):\n",
    "    nCategories = len(dataframe.columns)\n",
    "    df_list = dataframe.values.tolist()\n",
    "\n",
    "    df_plot = dataframe.copy(deep=True)\n",
    "    # delete sum column and row\n",
    "    df_plot.loc[\"Miss\"] = column_disagreement('CONTINGENCY')[:-1]\n",
    "    df_plot.loc[\"False Alarm\"] = row_disagreement('CONTINGENCY')[:-1]\n",
    "\n",
    "    # dynamically add labels in EntrySize plot based on x, y pos on plot\n",
    "    x_pos = []\n",
    "    for i in range(0, nCategories):\n",
    "        row_hit_sum = 0\n",
    "        for j in range(0, i):\n",
    "            row_hit_sum += (df_list[i][j])\n",
    "        row_hit_sum = (df_list[i][i] / 2) + row_hit_sum\n",
    "        x_pos.append(row_hit_sum)\n",
    "\n",
    "    fig = px.bar(df_plot, y=df_plot.index, x=df_plot.columns,\n",
    "                 height=350, orientation='h', width=600,\n",
    "                 opacity=1, color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "                 template=\"simple_white\")\n",
    "\n",
    "    layout = fig.update_layout(\n",
    "        font=dict(family=\"Trebuchet MS\", size=12),\n",
    "        hovermode=False,\n",
    "        paper_bgcolor='rgba(0,0,0,0)',\n",
    "        plot_bgcolor='rgba(0,0,0,0)',\n",
    "        yaxis=dict(autorange=\"reversed\", type='category', title='Table Feature',\n",
    "                   title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "        xaxis=dict(title='Entry size as number of Observations', dtick=1,\n",
    "                   title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\",\n",
    "                    x=0.8, title='',\n",
    "                    font=dict(family=\"Trebuchet MS\", size=12, color=\"black\"))\n",
    "    )\n",
    "\n",
    "    for i in range(0, nCategories):\n",
    "        fig.add_annotation(x=x_pos[i], y=i, text=\"Hit\", hovertext='Hits for Category 1', showarrow=False,\n",
    "                           font=dict(color='white',\n",
    "                                     family='Trebuchet MS',\n",
    "                                     size=12))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -i https://test.pypi.org/simple/ pontiPy==2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pontiPy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'sample.csv', index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pontiPy_Change(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.gain()\n",
    "sample.matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.entrySize_sam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df, y=df.index, x=df.columns,\n",
    "                height=350, orientation='h', width=600,\n",
    "                opacity=1, color_discrete_sequence=px.colors.qualitative.Set1,\n",
    "                template=\"simple_white\")\n",
    "layout = fig.update_layout(\n",
    "    font=dict(family=\"Trebuchet MS\", size=12),\n",
    "    hovermode=False,\n",
    "    paper_bgcolor='rgba(0,0,0,0)',\n",
    "    plot_bgcolor='rgba(0,0,0,0)',\n",
    "    yaxis=dict(autorange=\"reversed\", type='category', title='Table Feature',\n",
    "                title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "    xaxis=dict(title='Entry size as number of Observations', dtick=1,\n",
    "                title_font=dict(size=12, family='Trebuchet MS', color='black')),\n",
    "    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.02, xanchor=\"right\",\n",
    "                x=0.8, title='',\n",
    "                font=dict(family=\"Trebuchet MS\", size=12, color=\"black\"))\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
